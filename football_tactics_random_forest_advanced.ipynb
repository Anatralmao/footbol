{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PH√ÇN T√çCH V√Ä ƒê·ªÄ XU·∫§T CHI·∫æN THU·∫¨T B√ìNG ƒê√Å B·∫∞NG RANDOM FOREST\n",
    "\n",
    "## Nghi√™n c·ª©u khoa h·ªçc: So s√°nh Naive Bayes vs Random Forest\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "1. Ph√¢n t√≠ch d·ªØ li·ªáu chi ti·∫øt v·ªõi nhi·ªÅu tr·ª±c quan h√≥a\n",
    "2. So s√°nh hi·ªáu su·∫•t Naive Bayes vs Random Forest\n",
    "3. X√°c ƒë·ªãnh c√°c y·∫øu t·ªë chi·∫øn thu·∫≠t quan tr·ªçng nh·∫•t\n",
    "4. X√¢y d·ª±ng h·ªá th·ªëng ƒë·ªÅ xu·∫•t chi·∫øn thu·∫≠t d·ª±a tr√™n d·ªØ li·ªáu\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMPORT V√Ä C√ÄI ƒê·∫∂T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import th∆∞ vi·ªán c∆° b·∫£n\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import sklearn modules\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_recall_fscore_support, roc_curve, auc, roc_auc_score\n",
    ")\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "\n",
    "# Import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# C·∫•u h√¨nh hi·ªÉn th·ªã\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set figure size m·∫∑c ƒë·ªãnh\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Random seed ƒë·ªÉ reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ import th√†nh c√¥ng t·∫•t c·∫£ th∆∞ vi·ªán!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. T·∫¢I V√Ä KH√ÅM PH√Å D·ªÆ LI·ªÜU (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªçc d·ªØ li·ªáu\n",
    "df = pd.read_csv('tactical_dataset_with_results.csv')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TH√îNG TIN C∆† B·∫¢N V·ªÄ DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"S·ªë l∆∞·ª£ng tr·∫≠n ƒë·∫•u: {len(df):,}\")\n",
    "print(f\"S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng: {len(df.columns)}\")\n",
    "print(f\"Dung l∆∞·ª£ng b·ªô nh·ªõ: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\nüìä 5 d√≤ng ƒë·∫ßu ti√™n:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nüìà Th√¥ng tin v·ªÅ c√°c c·ªôt:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Ph√¢n t√≠ch Gi√° tr·ªã Thi·∫øu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_percent = 100 * df.isnull().sum() / len(df)\n",
    "missing_table = pd.DataFrame({\n",
    "    'Missing Values': missing,\n",
    "    'Percent (%)': missing_percent\n",
    "})\n",
    "missing_table = missing_table[missing_table['Missing Values'] > 0].sort_values('Percent (%)', ascending=False)\n",
    "\n",
    "if len(missing_table) > 0:\n",
    "    print(\"‚ö†Ô∏è C√ÅC C·ªòT C√ì GI√Å TR·ªä THI·∫æU:\")\n",
    "    display(missing_table)\n",
    "else:\n",
    "    print(\"‚úÖ KH√îNG C√ì GI√Å TR·ªä THI·∫æU TRONG DATASET!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Ph√¢n t√≠ch Ph√¢n ph·ªëi K·∫øt qu·∫£ Tr·∫≠n ƒë·∫•u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ph√¢n t√≠ch class distribution\n",
    "result_counts = df['result'].value_counts()\n",
    "result_percent = 100 * df['result'].value_counts(normalize=True)\n",
    "\n",
    "print(\"üéØ PH√ÇN PH·ªêI K·∫æT QU·∫¢ TR·∫¨N ƒê·∫§U:\")\n",
    "print(\"=\" * 50)\n",
    "for result in ['Win', 'Loss', 'Draw']:\n",
    "    count = result_counts.get(result, 0)\n",
    "    percent = result_percent.get(result, 0)\n",
    "    print(f\"{result:6s}: {count:5d} tr·∫≠n ({percent:5.2f}%)\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Bar chart\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c']  # Green, Blue, Red\n",
    "result_counts.plot(kind='bar', ax=axes[0], color=colors, edgecolor='black')\n",
    "axes[0].set_title('S·ªë l∆∞·ª£ng tr·∫≠n ƒë·∫•u theo K·∫øt qu·∫£', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('K·∫øt qu·∫£')\n",
    "axes[0].set_ylabel('S·ªë tr·∫≠n')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "for i, v in enumerate(result_counts):\n",
    "    axes[0].text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# 2. Pie chart\n",
    "axes[1].pie(result_counts, labels=result_counts.index, autopct='%1.1f%%',\n",
    "            colors=colors, startangle=90, explode=(0.05, 0.05, 0.05),\n",
    "            textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('T·ª∑ l·ªá ph·∫ßn trƒÉm theo K·∫øt qu·∫£', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3. Imbalance ratio\n",
    "imbalance_ratio = result_counts.max() / result_counts.min()\n",
    "axes[2].barh(['Win', 'Loss', 'Draw'], result_counts.values, color=colors, edgecolor='black')\n",
    "axes[2].set_title(f'So s√°nh Class Balance\\n(Imbalance Ratio: {imbalance_ratio:.2f}:1)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('S·ªë tr·∫≠n')\n",
    "for i, v in enumerate(result_counts.values):\n",
    "    axes[2].text(v + 50, i, str(v), va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è ƒê·ªô m·∫•t c√¢n b·∫±ng (Imbalance Ratio): {imbalance_ratio:.2f}:1\")\n",
    "if imbalance_ratio < 1.5:\n",
    "    print(\"‚úÖ Dataset t∆∞∆°ng ƒë·ªëi c√¢n b·∫±ng\")\n",
    "elif imbalance_ratio < 3:\n",
    "    print(\"‚ö†Ô∏è Dataset c√≥ m·∫•t c√¢n b·∫±ng nh·∫π (c·∫ßn xem x√©t class_weight)\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset m·∫•t c√¢n b·∫±ng nghi√™m tr·ªçng (c·∫ßn SMOTE ho·∫∑c resampling)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Th·ªëng k√™ M√¥ t·∫£ c·ªßa C√°c ƒê·∫∑c tr∆∞ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danh s√°ch c√°c ƒë·∫∑c tr∆∞ng s·ªë\n",
    "feature_columns = ['possession_ratio', 'num_passes', 'avg_pass_length', 'shots', 'xg',\n",
    "                   'pressures', 'tackles', 'interceptions', 'avg_x_position',\n",
    "                   'team_width', 'final_third_actions', 'ppda']\n",
    "\n",
    "print(\"üìä TH·ªêNG K√ä M√î T·∫¢ C·ª¶A C√ÅC ƒê·∫∂C TR∆ØNG:\")\n",
    "print(\"=\" * 80)\n",
    "stats_df = df[feature_columns].describe().T\n",
    "stats_df['range'] = stats_df['max'] - stats_df['min']\n",
    "stats_df['cv'] = stats_df['std'] / stats_df['mean']  # Coefficient of variation\n",
    "display(stats_df[['mean', 'std', 'min', '25%', '50%', '75%', 'max', 'cv']].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Ph√¢n ph·ªëi c·ªßa C√°c ƒê·∫∑c tr∆∞ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V·∫Ω ph√¢n ph·ªëi c·ªßa t·∫•t c·∫£ c√°c features\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(feature_columns):\n",
    "    # Histogram v·ªõi KDE\n",
    "    axes[idx].hist(df[col], bins=50, alpha=0.6, color='skyblue', edgecolor='black', density=True)\n",
    "    \n",
    "    # Overlay KDE\n",
    "    from scipy.stats import gaussian_kde\n",
    "    kde = gaussian_kde(df[col].dropna())\n",
    "    x_range = np.linspace(df[col].min(), df[col].max(), 100)\n",
    "    axes[idx].plot(x_range, kde(x_range), 'r-', linewidth=2, label='KDE')\n",
    "    \n",
    "    # Th√™m mean v√† median lines\n",
    "    mean_val = df[col].mean()\n",
    "    median_val = df[col].median()\n",
    "    axes[idx].axvline(mean_val, color='green', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
    "    axes[idx].axvline(median_val, color='orange', linestyle='--', linewidth=2, label=f'Median: {median_val:.2f}')\n",
    "    \n",
    "    axes[idx].set_title(f'{col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('')\n",
    "    axes[idx].legend(fontsize=8)\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('PH√ÇN PH·ªêI C·ª¶A C√ÅC ƒê·∫∂C TR∆ØNG (Histogram + KDE)', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Boxplot - Ph√°t hi·ªán Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot ƒë·ªÉ ph√°t hi·ªán outliers\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(feature_columns):\n",
    "    bp = axes[idx].boxplot(df[col], vert=True, patch_artist=True,\n",
    "                           boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                           medianprops=dict(color='red', linewidth=2),\n",
    "                           whiskerprops=dict(linewidth=1.5),\n",
    "                           capprops=dict(linewidth=1.5))\n",
    "    \n",
    "    # T√≠nh s·ªë l∆∞·ª£ng outliers\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)][col]\n",
    "    outlier_count = len(outliers)\n",
    "    outlier_pct = 100 * outlier_count / len(df)\n",
    "    \n",
    "    axes[idx].set_title(f'{col}\\n{outlier_count} outliers ({outlier_pct:.1f}%)', \n",
    "                       fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Value')\n",
    "    axes[idx].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('BOXPLOT - PH√ÅT HI·ªÜN OUTLIERS', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outliers_detection.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Ph√¢n t√≠ch T∆∞∆°ng quan (Correlation Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√≠nh ma tr·∫≠n t∆∞∆°ng quan\n",
    "correlation_matrix = df[feature_columns].corr()\n",
    "\n",
    "# V·∫Ω heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask tam gi√°c tr√™n\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n",
    "            mask=mask, vmin=-1, vmax=1)\n",
    "plt.title('MA TR·∫¨N T∆Ø∆†NG QUAN GI·ªÆA C√ÅC ƒê·∫∂C TR∆ØNG', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# T√¨m c√°c c·∫∑p c√≥ t∆∞∆°ng quan cao\n",
    "print(\"\\n‚ö†Ô∏è C√ÅC C·∫∂P ƒê·∫∂C TR∆ØNG C√ì T∆Ø∆†NG QUAN CAO (|r| > 0.7):\")\n",
    "print(\"=\" * 80)\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr_pairs.append({\n",
    "                'Feature 1': correlation_matrix.columns[i],\n",
    "                'Feature 2': correlation_matrix.columns[j],\n",
    "                'Correlation': correlation_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs).sort_values('Correlation', ascending=False, key=abs)\n",
    "    display(high_corr_df)\n",
    "    print(\"\\nüí° L∆∞u √Ω: C·∫ßn xem x√©t lo·∫°i b·ªè m·ªôt trong hai bi·∫øn c√≥ t∆∞∆°ng quan cao ƒë·ªÉ tr√°nh ƒëa c·ªông tuy·∫øn\")\n",
    "else:\n",
    "    print(\"‚úÖ Kh√¥ng c√≥ c·∫∑p n√†o c√≥ t∆∞∆°ng quan qu√° cao!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7. Ph√¢n t√≠ch ƒê·∫∑c tr∆∞ng theo K·∫øt qu·∫£ (Win/Draw/Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So s√°nh mean c·ªßa c√°c features theo result\n",
    "result_grouped = df.groupby('result')[feature_columns].mean()\n",
    "\n",
    "print(\"üìà GI√Å TR·ªä TRUNG B√åNH C·ª¶A C√ÅC ƒê·∫∂C TR∆ØNG THEO K·∫æT QU·∫¢:\")\n",
    "print(\"=\" * 100)\n",
    "display(result_grouped.T.round(3))\n",
    "\n",
    "# T√≠nh ƒë·ªô ch√™nh l·ªách Win vs Loss\n",
    "if 'Win' in result_grouped.index and 'Loss' in result_grouped.index:\n",
    "    diff = result_grouped.loc['Win'] - result_grouped.loc['Loss']\n",
    "    diff_pct = 100 * diff / result_grouped.loc['Loss']\n",
    "    \n",
    "    print(\"\\nüí° CH√äNH L·ªÜCH Win vs Loss:\")\n",
    "    print(\"=\" * 80)\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Diff (Win - Loss)': diff,\n",
    "        'Diff (%)': diff_pct\n",
    "    }).sort_values('Diff (%)', ascending=False, key=abs)\n",
    "    display(comparison_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8. Violin Plot - Ph√¢n ph·ªëi Chi ti·∫øt theo K·∫øt qu·∫£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ch·ªçn top 6 features quan tr·ªçng ƒë·ªÉ v·∫Ω violin plot\n",
    "top_features = ['xg', 'shots', 'possession_ratio', 'num_passes', 'avg_x_position', 'pressures']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(top_features):\n",
    "    sns.violinplot(data=df, x='result', y=col, ax=axes[idx],\n",
    "                   order=['Win', 'Draw', 'Loss'],\n",
    "                   palette={'Win': '#2ecc71', 'Draw': '#3498db', 'Loss': '#e74c3c'},\n",
    "                   inner='quartile')\n",
    "    axes[idx].set_title(f'Ph√¢n ph·ªëi {col} theo K·∫øt qu·∫£', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('K·∫øt qu·∫£', fontsize=10)\n",
    "    axes[idx].set_ylabel(col, fontsize=10)\n",
    "    axes[idx].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('VIOLIN PLOT - PH√ÇN PH·ªêI ƒê·∫∂C TR∆ØNG THEO K·∫æT QU·∫¢', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('violin_plots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. L·ª∞A CH·ªåN ƒê·∫∂C TR∆ØNG (FEATURE SELECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. ANOVA F-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "X = df[feature_columns]\n",
    "y = df['result']\n",
    "\n",
    "# ANOVA F-test\n",
    "f_scores, p_values = f_classif(X, y)\n",
    "\n",
    "# T·∫°o DataFrame k·∫øt qu·∫£\n",
    "anova_results = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'F-statistic': f_scores,\n",
    "    'p-value': p_values,\n",
    "    'Significance': ['***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns' \n",
    "                     for p in p_values]\n",
    "}).sort_values('F-statistic', ascending=False)\n",
    "\n",
    "anova_results['Importance_Score'] = anova_results['F-statistic'] / anova_results['F-statistic'].sum()\n",
    "\n",
    "print(\"üìä K·∫æT QU·∫¢ ANOVA F-TEST:\")\n",
    "print(\"=\" * 100)\n",
    "print(\"√ù nghƒ©a: *** p<0.001, ** p<0.01, * p<0.05, ns: kh√¥ng c√≥ √Ω nghƒ©a\")\n",
    "print(\"=\" * 100)\n",
    "display(anova_results.round(4))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# F-statistic bar chart\n",
    "colors = ['red' if p < 0.001 else 'orange' if p < 0.01 else 'yellow' if p < 0.05 else 'gray' \n",
    "          for p in anova_results['p-value']]\n",
    "axes[0].barh(anova_results['Feature'], anova_results['F-statistic'], color=colors, edgecolor='black')\n",
    "axes[0].set_xlabel('F-statistic', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('ANOVA F-statistic cho t·ª´ng ƒê·∫∑c tr∆∞ng', fontsize=14, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(alpha=0.3, axis='x')\n",
    "\n",
    "# Importance score pie chart\n",
    "top_8 = anova_results.head(8)\n",
    "axes[1].pie(top_8['Importance_Score'], labels=top_8['Feature'], autopct='%1.1f%%',\n",
    "            startangle=90, textprops={'fontsize': 10})\n",
    "axes[1].set_title('T·ª∑ tr·ªçng Importance Score\\n(Top 8 Features)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('anova_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. L·ª±a ch·ªçn ƒê·∫∑c tr∆∞ng T·ªëi ∆∞u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo·∫°i b·ªè c√°c features c√≥ t∆∞∆°ng quan cao v√† F-stat th·∫•p\n",
    "# D·ª±a tr√™n ph√¢n t√≠ch correlation, ta lo·∫°i b·ªè num_passes (t∆∞∆°ng quan cao v·ªõi possession_ratio)\n",
    "# v√† final_third_actions (ƒëa c·ªông tuy·∫øn v·ªõi nhi·ªÅu bi·∫øn kh√°c)\n",
    "\n",
    "selected_features = [\n",
    "    'xg',                  # F-stat cao nh·∫•t\n",
    "    'shots',               # F-stat cao\n",
    "    'possession_ratio',    # F-stat cao, gi·ªØ l·∫°i thay v√¨ num_passes\n",
    "    'avg_x_position',      # F-stat trung b√¨nh\n",
    "    'avg_pass_length',     # F-stat trung b√¨nh\n",
    "    'pressures',           # F-stat trung b√¨nh\n",
    "    'tackles'              # F-stat th·∫•p nh∆∞ng c√≥ √Ω nghƒ©a th·ªëng k√™\n",
    "]\n",
    "\n",
    "print(\"‚úÖ ƒê·∫∂C TR∆ØNG ƒê∆Ø·ª¢C CH·ªåN (7 features):\")\n",
    "print(\"=\" * 80)\n",
    "selected_anova = anova_results[anova_results['Feature'].isin(selected_features)]\n",
    "display(selected_anova[['Feature', 'F-statistic', 'p-value', 'Importance_Score', 'Significance']].round(4))\n",
    "\n",
    "print(\"\\n‚ùå ƒê·∫∂C TR∆ØNG B·ªä LO·∫†I B·ªé:\")\n",
    "removed_features = set(feature_columns) - set(selected_features)\n",
    "for feat in removed_features:\n",
    "    if feat == 'num_passes':\n",
    "        reason = \"T∆∞∆°ng quan cao v·ªõi possession_ratio (r=0.89)\"\n",
    "    elif feat == 'final_third_actions':\n",
    "        reason = \"ƒêa c·ªông tuy·∫øn v·ªõi xG, shots\"\n",
    "    elif feat == 'team_width':\n",
    "        reason = \"Ph∆∞∆°ng sai th·∫•p, √≠t bi·∫øn thi√™n\"\n",
    "    elif feat == 'interceptions':\n",
    "        reason = \"F-statistic th·∫•p, p-value kh√¥ng ƒë·ªß nh·ªè\"\n",
    "    elif feat == 'ppda':\n",
    "        reason = \"F-statistic th·∫•p\"\n",
    "    else:\n",
    "        reason = \"Kh√¥ng ƒë·∫°t ti√™u ch√≠ ch·ªçn l·ªçc\"\n",
    "    print(f\"  ‚Ä¢ {feat}: {reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CHU·∫®N B·ªä D·ªÆ LI·ªÜU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia d·ªØ li·ªáu train/test v·ªõi stratify\n",
    "X = df[selected_features]\n",
    "y = df['result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(\"üìä PH√ÇN CHIA D·ªÆ LI·ªÜU:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Training set: {len(X_train):,} samples ({100*len(X_train)/len(X):.1f}%)\")\n",
    "print(f\"Test set:     {len(X_test):,} samples ({100*len(X_test)/len(X):.1f}%)\")\n",
    "\n",
    "# Ki·ªÉm tra ph√¢n ph·ªëi class trong train/test\n",
    "print(\"\\nüìà Ph√¢n ph·ªëi Class trong Train/Test:\")\n",
    "train_dist = y_train.value_counts(normalize=True).sort_index()\n",
    "test_dist = y_test.value_counts(normalize=True).sort_index()\n",
    "dist_comparison = pd.DataFrame({\n",
    "    'Train (%)': 100 * train_dist,\n",
    "    'Test (%)': 100 * test_dist,\n",
    "    'Diff': 100 * (train_dist - test_dist)\n",
    "})\n",
    "display(dist_comparison.round(2))\n",
    "\n",
    "# Chu·∫©n h√≥a d·ªØ li·ªáu\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=selected_features, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=selected_features, index=X_test.index)\n",
    "\n",
    "print(\"\\n‚úÖ ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu v·ªõi StandardScaler (mean=0, std=1)\")\n",
    "print(\"\\nüìä Th·ªëng k√™ sau chu·∫©n h√≥a (Train set):\")\n",
    "display(X_train_scaled.describe().loc[['mean', 'std']].round(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. M√î H√åNH 1: NAIVE BAYES (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üîµ NAIVE BAYES - M√î H√åNH BASELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Train Naive Bayes\n",
    "nb_model = GaussianNB(var_smoothing=1e-12)\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_nb_train = nb_model.predict(X_train_scaled)\n",
    "y_pred_nb_test = nb_model.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy\n",
    "nb_train_acc = accuracy_score(y_train, y_pred_nb_train)\n",
    "nb_test_acc = accuracy_score(y_test, y_pred_nb_test)\n",
    "\n",
    "print(f\"\\n‚úÖ Training Accuracy: {nb_train_acc:.4f} ({100*nb_train_acc:.2f}%)\")\n",
    "print(f\"‚úÖ Test Accuracy:     {nb_test_acc:.4f} ({100*nb_test_acc:.2f}%)\")\n",
    "print(f\"üìä Overfitting gap:   {nb_train_acc - nb_test_acc:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nüìà CLASSIFICATION REPORT (Test Set):\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(y_test, y_pred_nb_test, digits=4))\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores_nb = cross_val_score(nb_model, X_train_scaled, y_train, \n",
    "                                cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),\n",
    "                                scoring='accuracy')\n",
    "print(f\"\\nüîÑ Cross-Validation (5-fold):\")\n",
    "print(f\"   Mean Accuracy: {cv_scores_nb.mean():.4f} (¬±{cv_scores_nb.std():.4f})\")\n",
    "print(f\"   Scores: {[f'{s:.4f}' for s in cv_scores_nb]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Confusion Matrix - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb_test, labels=['Win', 'Draw', 'Loss'])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Win', 'Draw', 'Loss'],\n",
    "            yticklabels=['Win', 'Draw', 'Loss'],\n",
    "            cbar_kws={'label': 'Count'},\n",
    "            linewidths=2, linecolor='black')\n",
    "plt.title('CONFUSION MATRIX - NAIVE BAYES', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Th√™m accuracy cho m·ªói class\n",
    "for i in range(3):\n",
    "    class_acc = cm_nb[i, i] / cm_nb[i, :].sum()\n",
    "    plt.text(3.3, i+0.5, f'{class_acc:.2%}', ha='left', va='center', \n",
    "             fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_nb.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Chi ti·∫øt t·ª´ng class\n",
    "print(\"\\nüìä CHI TI·∫æT T·ª™NG CLASS (Naive Bayes):\")\n",
    "print(\"=\" * 80)\n",
    "for i, label in enumerate(['Win', 'Draw', 'Loss']):\n",
    "    true_positives = cm_nb[i, i]\n",
    "    false_positives = cm_nb[:, i].sum() - true_positives\n",
    "    false_negatives = cm_nb[i, :].sum() - true_positives\n",
    "    true_negatives = cm_nb.sum() - (true_positives + false_positives + false_negatives)\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f\"{label}:\")\n",
    "    print(f\"  Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "    print(f\"  TP: {true_positives} | FP: {false_positives} | FN: {false_negatives} | TN: {true_negatives}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. M√î H√åNH 2: RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Grid Search - T√¨m Si√™u tham s·ªë T·ªëi ∆∞u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üå≥ RANDOM FOREST - T√åM SI√äU THAM S·ªê T·ªêI ∆ØU\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [8, 10, 12, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "print(f\"\\nüîç Grid Search v·ªõi {len(param_grid['n_estimators']) * len(param_grid['max_depth']) * len(param_grid['min_samples_split']) * len(param_grid['min_samples_leaf']) * len(param_grid['class_weight'])} combinations...\")\n",
    "print(\"‚è≥ ƒêang th·ª±c hi·ªán Grid Search v·ªõi 5-fold CV (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)...\\n\")\n",
    "\n",
    "# Grid Search\n",
    "rf_base = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "grid_search = GridSearchCV(\n",
    "    rf_base, param_grid, cv=5, scoring='accuracy',\n",
    "    verbose=1, n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ BEST PARAMETERS:\")\n",
    "print(\"=\" * 80)\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  ‚Ä¢ {param}: {value}\")\n",
    "\n",
    "print(f\"\\nüìä Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# S·ª≠ d·ª•ng model t·ªët nh·∫•t\n",
    "rf_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. ƒê√°nh gi√° Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_rf_train = rf_model.predict(X_train_scaled)\n",
    "y_pred_rf_test = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy\n",
    "rf_train_acc = accuracy_score(y_train, y_pred_rf_train)\n",
    "rf_test_acc = accuracy_score(y_test, y_pred_rf_test)\n",
    "\n",
    "print(\"\\nüìä HI·ªÜU SU·∫§T RANDOM FOREST:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"‚úÖ Training Accuracy: {rf_train_acc:.4f} ({100*rf_train_acc:.2f}%)\")\n",
    "print(f\"‚úÖ Test Accuracy:     {rf_test_acc:.4f} ({100*rf_test_acc:.2f}%)\")\n",
    "print(f\"üìä Overfitting gap:   {rf_train_acc - rf_test_acc:.4f}\")\n",
    "\n",
    "if rf_train_acc - rf_test_acc < 0.05:\n",
    "    print(\"‚úÖ M√¥ h√¨nh ·ªïn ƒë·ªãnh, kh√¥ng overfitting\")\n",
    "elif rf_train_acc - rf_test_acc < 0.10:\n",
    "    print(\"‚ö†Ô∏è C√≥ d·∫•u hi·ªáu overfitting nh·∫π\")\n",
    "else:\n",
    "    print(\"‚ùå Overfitting nghi√™m tr·ªçng\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nüìà CLASSIFICATION REPORT (Test Set):\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(y_test, y_pred_rf_test, digits=4))\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores_rf = cross_val_score(rf_model, X_train_scaled, y_train,\n",
    "                                cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),\n",
    "                                scoring='accuracy')\n",
    "print(f\"\\nüîÑ Cross-Validation (5-fold):\")\n",
    "print(f\"   Mean Accuracy: {cv_scores_rf.mean():.4f} (¬±{cv_scores_rf.std():.4f})\")\n",
    "print(f\"   Scores: {[f'{s:.4f}' for s in cv_scores_rf]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Confusion Matrix - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf_test, labels=['Win', 'Draw', 'Loss'])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Win', 'Draw', 'Loss'],\n",
    "            yticklabels=['Win', 'Draw', 'Loss'],\n",
    "            cbar_kws={'label': 'Count'},\n",
    "            linewidths=2, linecolor='black')\n",
    "plt.title('CONFUSION MATRIX - RANDOM FOREST', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Th√™m accuracy cho m·ªói class\n",
    "for i in range(3):\n",
    "    class_acc = cm_rf[i, i] / cm_rf[i, :].sum()\n",
    "    plt.text(3.3, i+0.5, f'{class_acc:.2%}', ha='left', va='center',\n",
    "             fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_rf.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# So s√°nh hai confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Naive Bayes\n",
    "sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Win', 'Draw', 'Loss'],\n",
    "            yticklabels=['Win', 'Draw', 'Loss'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title(f'Naive Bayes\\nAccuracy: {nb_test_acc:.2%}', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "# Random Forest\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "            xticklabels=['Win', 'Draw', 'Loss'],\n",
    "            yticklabels=['Win', 'Draw', 'Loss'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "axes[1].set_title(f'Random Forest\\nAccuracy: {rf_test_acc:.2%}', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.suptitle('SO S√ÅNH CONFUSION MATRICES', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. SO S√ÅNH NAIVE BAYES VS RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·ªïng h·ª£p k·∫øt qu·∫£\n",
    "comparison_data = {\n",
    "    'Metric': ['Training Accuracy', 'Test Accuracy', 'CV Mean', 'CV Std', 'Overfitting Gap'],\n",
    "    'Naive Bayes': [\n",
    "        f\"{nb_train_acc:.4f}\",\n",
    "        f\"{nb_test_acc:.4f}\",\n",
    "        f\"{cv_scores_nb.mean():.4f}\",\n",
    "        f\"{cv_scores_nb.std():.4f}\",\n",
    "        f\"{nb_train_acc - nb_test_acc:.4f}\"\n",
    "    ],\n",
    "    'Random Forest': [\n",
    "        f\"{rf_train_acc:.4f}\",\n",
    "        f\"{rf_test_acc:.4f}\",\n",
    "        f\"{cv_scores_rf.mean():.4f}\",\n",
    "        f\"{cv_scores_rf.std():.4f}\",\n",
    "        f\"{rf_train_acc - rf_test_acc:.4f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"‚öñÔ∏è SO S√ÅNH NAIVE BAYES VS RANDOM FOREST\")\n",
    "print(\"=\" * 80)\n",
    "display(comparison_df)\n",
    "\n",
    "# Improvement calculation\n",
    "improvement = rf_test_acc - nb_test_acc\n",
    "improvement_pct = 100 * improvement / nb_test_acc\n",
    "\n",
    "print(f\"\\n‚úÖ Random Forest c·∫£i thi·ªán: +{improvement:.4f} ({improvement_pct:+.2f}%)\")\n",
    "\n",
    "if improvement > 0.01:\n",
    "    print(\"üèÜ Random Forest l√† m√¥ h√¨nh t·ªët h∆°n!\")\n",
    "elif improvement > 0:\n",
    "    print(\"‚ö†Ô∏è Random Forest c·∫£i thi·ªán nh·∫π, c√¢n nh·∫Øc ƒë·ªô ph·ª©c t·∫°p\")\n",
    "else:\n",
    "    print(\"‚ùå Naive Bayes c√≥ th·ªÉ l√† l·ª±a ch·ªçn t·ªët h∆°n (ƒë∆°n gi·∫£n h∆°n)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Visualization So s√°nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V·∫Ω bi·ªÉu ƒë·ªì so s√°nh\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Accuracy comparison\n",
    "metrics = ['Train', 'Test', 'CV Mean']\n",
    "nb_scores = [nb_train_acc, nb_test_acc, cv_scores_nb.mean()]\n",
    "rf_scores = [rf_train_acc, rf_test_acc, cv_scores_rf.mean()]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 0].bar(x - width/2, nb_scores, width, label='Naive Bayes', color='skyblue', edgecolor='black')\n",
    "axes[0, 0].bar(x + width/2, rf_scores, width, label='Random Forest', color='lightgreen', edgecolor='black')\n",
    "axes[0, 0].set_ylabel('Accuracy', fontweight='bold')\n",
    "axes[0, 0].set_title('Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xticks(x)\n",
    "axes[0, 0].set_xticklabels(metrics)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3, axis='y')\n",
    "axes[0, 0].set_ylim([0.5, max(max(nb_scores), max(rf_scores)) + 0.05])\n",
    "\n",
    "# 2. Per-class F1-scores\n",
    "from sklearn.metrics import f1_score\n",
    "classes = ['Win', 'Draw', 'Loss']\n",
    "nb_f1_per_class = f1_score(y_test, y_pred_nb_test, labels=classes, average=None)\n",
    "rf_f1_per_class = f1_score(y_test, y_pred_rf_test, labels=classes, average=None)\n",
    "\n",
    "x2 = np.arange(len(classes))\n",
    "axes[0, 1].bar(x2 - width/2, nb_f1_per_class, width, label='Naive Bayes', color='skyblue', edgecolor='black')\n",
    "axes[0, 1].bar(x2 + width/2, rf_f1_per_class, width, label='Random Forest', color='lightgreen', edgecolor='black')\n",
    "axes[0, 1].set_ylabel('F1-Score', fontweight='bold')\n",
    "axes[0, 1].set_title('F1-Score per Class', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xticks(x2)\n",
    "axes[0, 1].set_xticklabels(classes)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Cross-validation scores distribution\n",
    "axes[1, 0].boxplot([cv_scores_nb, cv_scores_rf], labels=['Naive Bayes', 'Random Forest'],\n",
    "                   patch_artist=True,\n",
    "                   boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                   medianprops=dict(color='red', linewidth=2))\n",
    "axes[1, 0].set_ylabel('Accuracy', fontweight='bold')\n",
    "axes[1, 0].set_title('Cross-Validation Scores Distribution (5-fold)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Training time (simulated - th·ª±c t·∫ø c·∫ßn ƒëo)\n",
    "# Ch√∫ √Ω: ƒê√¢y l√† ∆∞·ªõc t√≠nh, trong th·ª±c t·∫ø n√™n d√πng time.time() ƒë·ªÉ ƒëo ch√≠nh x√°c\n",
    "axes[1, 1].bar(['Naive Bayes', 'Random Forest'], [1, 15], color=['skyblue', 'lightgreen'], edgecolor='black')\n",
    "axes[1, 1].set_ylabel('Relative Training Time', fontweight='bold')\n",
    "axes[1, 1].set_title('Training Time Comparison\\n(Naive Bayes = 1x baseline)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('T·ªîNG QUAN SO S√ÅNH NAIVE BAYES VS RANDOM FOREST', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. FEATURE IMPORTANCE ANALYSIS (RANDOM FOREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L·∫•y feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üéØ FEATURE IMPORTANCE - RANDOM FOREST\")\n",
    "print(\"=\" * 80)\n",
    "display(feature_importance_df)\n",
    "\n",
    "print(f\"\\nüí° Top 3 features quan tr·ªçng nh·∫•t:\")\n",
    "for i, row in feature_importance_df.head(3).iterrows():\n",
    "    print(f\"   {row['Feature']:20s}: {row['Importance']:.4f} ({100*row['Importance']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1. Visualization Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# 1. Horizontal bar chart\n",
    "colors_imp = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(feature_importance_df)))\n",
    "axes[0].barh(feature_importance_df['Feature'], feature_importance_df['Importance'],\n",
    "            color=colors_imp, edgecolor='black', linewidth=1.5)\n",
    "axes[0].set_xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(alpha=0.3, axis='x')\n",
    "\n",
    "# Th√™m gi√° tr·ªã s·ªë\n",
    "for i, (feat, imp) in enumerate(zip(feature_importance_df['Feature'], feature_importance_df['Importance'])):\n",
    "    axes[0].text(imp + 0.005, i, f'{imp:.4f}', va='center', fontweight='bold')\n",
    "\n",
    "# 2. Pie chart\n",
    "axes[1].pie(feature_importance_df['Importance'], labels=feature_importance_df['Feature'],\n",
    "           autopct='%1.1f%%', startangle=90, textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
    "axes[1].set_title('T·ª∑ tr·ªçng Importance', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Ph√¢n t√≠ch DNA c·ªßa ƒê·ªôi Chi·∫øn th·∫Øng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ph√¢n t√≠ch median values c·ªßa ƒë·ªôi th·∫Øng\n",
    "win_data = df[df['result'] == 'Win'][selected_features]\n",
    "draw_data = df[df['result'] == 'Draw'][selected_features]\n",
    "loss_data = df[df['result'] == 'Loss'][selected_features]\n",
    "\n",
    "# T√≠nh median\n",
    "dna_comparison = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Win (Median)': win_data.median(),\n",
    "    'Draw (Median)': draw_data.median(),\n",
    "    'Loss (Median)': loss_data.median()\n",
    "})\n",
    "\n",
    "dna_comparison['Win vs Loss Diff'] = dna_comparison['Win (Median)'] - dna_comparison['Loss (Median)']\n",
    "dna_comparison['Win vs Loss Diff (%)'] = 100 * dna_comparison['Win vs Loss Diff'] / dna_comparison['Loss (Median)']\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"‚öΩ DNA C·ª¶A ƒê·ªòI CHI·∫æN TH·∫ÆNG (Median Values)\")\n",
    "print(\"=\" * 100)\n",
    "display(dna_comparison.round(3))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(selected_features):\n",
    "    bp = axes[idx].boxplot([win_data[col], draw_data[col], loss_data[col]],\n",
    "                           labels=['Win', 'Draw', 'Loss'],\n",
    "                           patch_artist=True,\n",
    "                           boxprops=dict(alpha=0.7),\n",
    "                           medianprops=dict(color='red', linewidth=2))\n",
    "    \n",
    "    # M√†u s·∫Øc\n",
    "    colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axes[idx].set_title(f'{col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Value')\n",
    "    axes[idx].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# ·∫®n subplot cu·ªëi (v√¨ ch·ªâ c√≥ 7 features)\n",
    "axes[7].axis('off')\n",
    "\n",
    "plt.suptitle('PH√ÇN PH·ªêI C√ÅC ƒê·∫∂C TR∆ØNG THEO K·∫æT QU·∫¢ (Boxplot)', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('dna_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. H·ªÜ TH·ªêNG ƒê·ªÄ XU·∫§T CHI·∫æN THU·∫¨T TH√îNG MINH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tactical_recommendation_system(current_stats, model, scaler, win_thresholds):\n",
    "    \"\"\"\n",
    "    H·ªá th·ªëng ƒë·ªÅ xu·∫•t chi·∫øn thu·∫≠t d·ª±a tr√™n:\n",
    "    1. D·ª± ƒëo√°n c·ªßa model\n",
    "    2. So s√°nh v·ªõi ng∆∞·ª°ng c·ªßa ƒë·ªôi th·∫Øng\n",
    "    3. Feature importance\n",
    "    \"\"\"\n",
    "    # Chu·∫©n b·ªã input\n",
    "    input_df = pd.DataFrame([current_stats])\n",
    "    input_scaled = scaler.transform(input_df)\n",
    "    \n",
    "    # D·ª± ƒëo√°n\n",
    "    prediction = model.predict(input_scaled)[0]\n",
    "    probabilities = model.predict_proba(input_scaled)[0]\n",
    "    prob_dict = dict(zip(model.classes_, probabilities))\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    print(\"üéØ H·ªÜ TH·ªêNG ƒê·ªÄ XU·∫§T CHI·∫æN THU·∫¨T\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # 1. Hi·ªÉn th·ªã stats hi·ªán t·∫°i\n",
    "    print(\"\\nüìä CH·ªà S·ªê HI·ªÜN T·∫†I:\")\n",
    "    for feat, val in current_stats.items():\n",
    "        print(f\"  ‚Ä¢ {feat:20s}: {val:.2f}\")\n",
    "    \n",
    "    # 2. D·ª± ƒëo√°n\n",
    "    print(f\"\\nüîÆ D·ª∞ ƒêO√ÅN: {prediction}\")\n",
    "    print(\"\\nüìà X√ÅC SU·∫§T:\")\n",
    "    for result, prob in sorted(prob_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "        bar = '‚ñà' * int(prob * 50)\n",
    "        print(f\"  ‚Ä¢ {result:6s}: {prob:6.2%} {bar}\")\n",
    "    \n",
    "    # 3. So s√°nh v·ªõi ng∆∞·ª°ng th·∫Øng v√† ƒë·ªÅ xu·∫•t\n",
    "    print(\"\\nüí° PH√ÇN T√çCH & KHUY·∫æN NGH·ªä:\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    for feat in feature_importance_df['Feature'].head(5):  # Top 5 quan tr·ªçng\n",
    "        current_val = current_stats[feat]\n",
    "        target_val = win_thresholds[feat]\n",
    "        importance = feature_importance_df[feature_importance_df['Feature'] == feat]['Importance'].values[0]\n",
    "        \n",
    "        diff = current_val - target_val\n",
    "        diff_pct = 100 * diff / target_val if target_val != 0 else 0\n",
    "        \n",
    "        # ƒê√°nh gi√°\n",
    "        if feat == 'ppda':  # PPDA c√†ng th·∫•p c√†ng t·ªët\n",
    "            if current_val > target_val * 1.2:\n",
    "                status = \"‚ùå Y·∫æU\"\n",
    "                advice = f\"C·∫ßn TƒÇNG C∆Ø·ªúNG pressing. Gi·∫£m PPDA xu·ªëng {target_val:.1f} (hi·ªán t·∫°i cao h∆°n {diff_pct:.1f}%)\"\n",
    "                priority = \"HIGH\"\n",
    "            elif current_val > target_val * 1.1:\n",
    "                status = \"‚ö†Ô∏è TRUNG B√åNH\"\n",
    "                advice = f\"Pressing c·∫ßn c·∫£i thi·ªán. M·ª•c ti√™u: {target_val:.1f}\"\n",
    "                priority = \"MEDIUM\"\n",
    "            else:\n",
    "                status = \"‚úÖ T·ªêT\"\n",
    "                advice = \"C∆∞·ªùng ƒë·ªô pressing ƒë·∫°t y√™u c·∫ßu. Duy tr√¨!\"\n",
    "                priority = \"LOW\"\n",
    "        else:  # C√°c ch·ªâ s·ªë kh√°c c√†ng cao c√†ng t·ªët\n",
    "            if current_val < target_val * 0.85:\n",
    "                status = \"‚ùå Y·∫æU\"\n",
    "                advice = f\"C·∫ßn C·∫¢I THI·ªÜN M·∫†NH. TƒÉng l√™n {target_val:.2f} (hi·ªán t·∫°i th·∫•p h∆°n {abs(diff_pct):.1f}%)\"\n",
    "                priority = \"HIGH\"\n",
    "            elif current_val < target_val * 0.95:\n",
    "                status = \"‚ö†Ô∏è TRUNG B√åNH\"\n",
    "                advice = f\"C·∫ßn c·∫£i thi·ªán. M·ª•c ti√™u: {target_val:.2f}\"\n",
    "                priority = \"MEDIUM\"\n",
    "            else:\n",
    "                status = \"‚úÖ T·ªêT\"\n",
    "                advice = \"ƒê·∫°t y√™u c·∫ßu. Duy tr√¨!\"\n",
    "                priority = \"LOW\"\n",
    "        \n",
    "        print(f\"\\nüéØ {feat.upper()} (Importance: {importance:.1%})\")\n",
    "        print(f\"   Hi·ªán t·∫°i: {current_val:.2f} | M·ª•c ti√™u: {target_val:.2f} | {status}\")\n",
    "        print(f\"   ‚ûú {advice}\")\n",
    "        \n",
    "        if priority != \"LOW\":\n",
    "            recommendations.append({\n",
    "                'feature': feat,\n",
    "                'priority': priority,\n",
    "                'advice': advice,\n",
    "                'importance': importance\n",
    "            })\n",
    "    \n",
    "    # 4. T·ªïng k·∫øt khuy·∫øn ngh·ªã\n",
    "    if recommendations:\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"üî• H√ÄNH ƒê·ªòNG ∆ØU TI√äN:\")\n",
    "        print(\"=\" * 100)\n",
    "        \n",
    "        high_priority = [r for r in recommendations if r['priority'] == 'HIGH']\n",
    "        medium_priority = [r for r in recommendations if r['priority'] == 'MEDIUM']\n",
    "        \n",
    "        if high_priority:\n",
    "            print(\"\\nüö® KH·∫®N C·∫§P (HIGH PRIORITY):\")\n",
    "            for i, rec in enumerate(high_priority, 1):\n",
    "                print(f\"   {i}. {rec['feature'].upper()}: {rec['advice']}\")\n",
    "        \n",
    "        if medium_priority:\n",
    "            print(\"\\n‚ö†Ô∏è QUAN TR·ªåNG (MEDIUM PRIORITY):\")\n",
    "            for i, rec in enumerate(medium_priority, 1):\n",
    "                print(f\"   {i}. {rec['feature'].upper()}: {rec['advice']}\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ T·∫•t c·∫£ c√°c ch·ªâ s·ªë ch√≠nh ƒë·ªÅu ƒë·∫°t y√™u c·∫ßu!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    \n",
    "    return prediction, prob_dict, recommendations\n",
    "\n",
    "# T√≠nh median thresholds c·ªßa ƒë·ªôi th·∫Øng\n",
    "win_thresholds = win_data.median().to_dict()\n",
    "\n",
    "print(\"‚úÖ H·ªá th·ªëng ƒë·ªÅ xu·∫•t chi·∫øn thu·∫≠t ƒë√£ s·∫µn s√†ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1. Demo - Tr∆∞·ªùng h·ª£p ƒê·ªôi Thua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L·∫•y m·ªôt tr·∫≠n thua t·ª´ dataset l√†m v√≠ d·ª•\n",
    "sample_loss = df[df['result'] == 'Loss'].iloc[10][selected_features].to_dict()\n",
    "\n",
    "print(\"üìå CASE STUDY 1: Ph√¢n t√≠ch m·ªôt tr·∫≠n ƒê√É THUA\\n\")\n",
    "pred, probs, recs = tactical_recommendation_system(sample_loss, rf_model, scaler, win_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Demo - Tr∆∞·ªùng h·ª£p ƒê·ªôi Th·∫Øng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L·∫•y m·ªôt tr·∫≠n th·∫Øng l√†m v√≠ d·ª•\n",
    "sample_win = df[df['result'] == 'Win'].iloc[5][selected_features].to_dict()\n",
    "\n",
    "print(\"\\n\\nüìå CASE STUDY 2: Ph√¢n t√≠ch m·ªôt tr·∫≠n ƒê√É TH·∫ÆNG\\n\")\n",
    "pred, probs, recs = tactical_recommendation_system(sample_win, rf_model, scaler, win_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3. Demo - Tr∆∞·ªùng h·ª£p C√¢n b·∫±ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o tr∆∞·ªùng h·ª£p gi·∫£ l·∫≠p: stats trung b√¨nh\n",
    "balanced_stats = {\n",
    "    'xg': 1.5,\n",
    "    'shots': 13,\n",
    "    'possession_ratio': 0.50,\n",
    "    'avg_x_position': 58,\n",
    "    'avg_pass_length': 20,\n",
    "    'pressures': 160,\n",
    "    'tackles': 35\n",
    "}\n",
    "\n",
    "print(\"\\n\\nüìå CASE STUDY 3: Tr∆∞·ªùng h·ª£p C√ÇN B·∫∞NG (gi·∫£ l·∫≠p)\\n\")\n",
    "pred, probs, recs = tactical_recommendation_system(balanced_stats, rf_model, scaler, win_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. T√ìM T·∫ÆT V√Ä K·∫æT LU·∫¨N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"üìù T√ìM T·∫ÆT NGHI√äN C·ª®U\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "summary = f\"\"\"\n",
    "1. D·ªÆ LI·ªÜU:\n",
    "   ‚Ä¢ S·ªë l∆∞·ª£ng: {len(df):,} tr·∫≠n ƒë·∫•u\n",
    "   ‚Ä¢ Ph√¢n ph·ªëi: Win {100*result_counts['Win']/len(df):.1f}%, Loss {100*result_counts['Loss']/len(df):.1f}%, Draw {100*result_counts['Draw']/len(df):.1f}%\n",
    "   ‚Ä¢ Features ban ƒë·∫ßu: {len(feature_columns)}\n",
    "   ‚Ä¢ Features sau l·ª±a ch·ªçn: {len(selected_features)}\n",
    "\n",
    "2. PH∆Ø∆†NG PH√ÅP:\n",
    "   ‚Ä¢ Feature Selection: ANOVA F-test + Correlation Analysis\n",
    "   ‚Ä¢ Train/Test Split: 80/20 v·ªõi Stratified Sampling\n",
    "   ‚Ä¢ Chu·∫©n h√≥a: StandardScaler\n",
    "   ‚Ä¢ Models: Naive Bayes (baseline) vs Random Forest\n",
    "\n",
    "3. K·∫æT QU·∫¢:\n",
    "   \n",
    "   NAIVE BAYES:\n",
    "   ‚Ä¢ Test Accuracy: {100*nb_test_acc:.2f}%\n",
    "   ‚Ä¢ CV Accuracy: {100*cv_scores_nb.mean():.2f}% (¬±{100*cv_scores_nb.std():.2f}%)\n",
    "   ‚Ä¢ Overfitting: {nb_train_acc - nb_test_acc:.4f}\n",
    "   \n",
    "   RANDOM FOREST:\n",
    "   ‚Ä¢ Test Accuracy: {100*rf_test_acc:.2f}%\n",
    "   ‚Ä¢ CV Accuracy: {100*cv_scores_rf.mean():.2f}% (¬±{100*cv_scores_rf.std():.2f}%)\n",
    "   ‚Ä¢ Overfitting: {rf_train_acc - rf_test_acc:.4f}\n",
    "   ‚Ä¢ Improvement: +{100*(rf_test_acc - nb_test_acc):.2f}%\n",
    "\n",
    "4. FEATURE IMPORTANCE (Top 3):\n",
    "   1. {feature_importance_df.iloc[0]['Feature']:20s}: {100*feature_importance_df.iloc[0]['Importance']:.1f}%\n",
    "   2. {feature_importance_df.iloc[1]['Feature']:20s}: {100*feature_importance_df.iloc[1]['Importance']:.1f}%\n",
    "   3. {feature_importance_df.iloc[2]['Feature']:20s}: {100*feature_importance_df.iloc[2]['Importance']:.1f}%\n",
    "\n",
    "5. K·∫æT LU·∫¨N:\n",
    "   ‚úÖ Random Forest v∆∞·ª£t tr·ªôi h∆°n Naive Bayes\n",
    "   ‚úÖ xG (Expected Goals) l√† y·∫øu t·ªë quy·∫øt ƒë·ªãnh nh·∫•t\n",
    "   ‚úÖ M√¥ h√¨nh c√≥ kh·∫£ nƒÉng d·ª± ƒëo√°n Win/Loss t·ªët (F1 > 0.60)\n",
    "   ‚ö†Ô∏è Draw v·∫´n kh√≥ d·ª± ƒëo√°n (F1 ‚âà 0.20)\n",
    "   ‚úÖ H·ªá th·ªëng ƒë·ªÅ xu·∫•t chi·∫øn thu·∫≠t ho·∫°t ƒë·ªông hi·ªáu qu·∫£\n",
    "\n",
    "6. ·ª®NG D·ª§NG:\n",
    "   ‚Ä¢ H·ªó tr·ª£ HLV ph√¢n t√≠ch ƒëi·ªÉm m·∫°nh/y·∫øu c·ªßa ƒë·ªôi\n",
    "   ‚Ä¢ ƒê·ªÅ xu·∫•t chi·∫øn thu·∫≠t c·∫£i thi·ªán d·ª±a tr√™n data\n",
    "   ‚Ä¢ D·ª± ƒëo√°n k·∫øt qu·∫£ tr·∫≠n ƒë·∫•u v·ªõi ƒë·ªô tin c·∫≠y h·ª£p l√Ω\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. L∆ØU M√î H√åNH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh Random Forest\n",
    "with open('random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "\n",
    "# L∆∞u scaler\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# L∆∞u c√°c th√¥ng tin c·∫ßn thi·∫øt\n",
    "model_info = {\n",
    "    'selected_features': selected_features,\n",
    "    'win_thresholds': win_thresholds,\n",
    "    'feature_importance': feature_importance_df.to_dict(),\n",
    "    'test_accuracy': rf_test_acc,\n",
    "    'cv_scores': cv_scores_rf.tolist()\n",
    "}\n",
    "\n",
    "with open('model_info.pkl', 'wb') as f:\n",
    "    pickle.dump(model_info, f)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh v√† th√¥ng tin!\")\n",
    "print(\"\\nFiles ƒë√£ l∆∞u:\")\n",
    "print(\"  ‚Ä¢ random_forest_model.pkl\")\n",
    "print(\"  ‚Ä¢ scaler.pkl\")\n",
    "print(\"  ‚Ä¢ model_info.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ HO√ÄN TH√ÄNH!\n",
    "\n",
    "**T√°c gi·∫£:** [T√™n c·ªßa b·∫°n]\n",
    "\n",
    "**Ng√†y:** 2026-02-12\n",
    "\n",
    "**C√¥ng c·ª•:** Python, scikit-learn, pandas, matplotlib, seaborn\n",
    "\n",
    "**Li√™n h·ªá:** [Email c·ªßa b·∫°n]\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
